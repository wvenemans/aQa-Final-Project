{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aQa Final Project: Qualitive comparison of Quantum Neural Networks and Classical Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, import the correct libraries. This may take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import cirq\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will define the depth and the number of qubits. We can sweep these variables later. <br>\n",
    "We can also generate the rotations that will generate the random data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(18)\n",
    "depth = 3\n",
    "n_qubits = 3\n",
    "\n",
    "randomRotations = np.random.uniform(-2*np.pi , 2 * np.pi, (depth * n_qubits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Circuits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define the quantum neural network. This is a simple circuit with a few layers of rotations and entanglements. We will use this circuit to classify the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildQuantumModel(encoding: np.array, parameters: np.array, depth : int, n_qubits : int) -> None:\n",
    "    qubits = cirq.LineQubit.range(n_qubits)\n",
    "\n",
    "    #encoding layer\n",
    "    yield [cirq.ry(encoding[i])(qubits[i]) for i in range(n_qubits)]\n",
    "    yield [cirq.rx(encoding[i])(qubits[i]) for i in range(n_qubits)]\n",
    "\n",
    "    #variational layer\n",
    "    for l in range(depth):\n",
    "        for i in range(n_qubits):\n",
    "            yield cirq.rx(parameters[i + l*n_qubits])(qubits[i])\n",
    "        for i in range(n_qubits-1):\n",
    "            yield cirq.CZ(qubits[i], qubits[i+1])\n",
    "\n",
    "\n",
    "    #readout layer\n",
    "    yield cirq.measure(qubits[0], key='z0')\n",
    "\n",
    "simulator = cirq.Simulator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, we define the `partial quantum model`, which has the same structure as the quantum neural network, but with an extra encoding layer inbetween even layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildPartialQuantumModel(encoding: np.array, parameters: np.array, depth : int, n_qubits : int) -> None:\n",
    "    qubits = cirq.LineQubit.range(n_qubits)\n",
    "\n",
    "    #encoding layer\n",
    "    yield [cirq.ry(encoding[i])(qubits[i]) for i in range(n_qubits)]\n",
    "    yield [cirq.rx(encoding[i])(qubits[i]) for i in range(n_qubits)]\n",
    "\n",
    "\n",
    "\n",
    "    #variational layer\n",
    "    for l in range(depth):\n",
    "        for i in range(n_qubits):\n",
    "            yield cirq.rx(parameters[i + l*n_qubits])(qubits[i])\n",
    "        for i in range(n_qubits-1):\n",
    "            yield cirq.CZ(qubits[i], qubits[i+1])\n",
    "\n",
    "        if l % 2 == 0:\n",
    "            yield [cirq.ry(encoding[i])(qubits[i]) for i in range(n_qubits)]\n",
    "            yield [cirq.rx(encoding[i])(qubits[i]) for i in range(n_qubits)]\n",
    "\n",
    "\n",
    "    #readout layer\n",
    "    yield cirq.measure(qubits[0], key='z0')\n",
    "\n",
    "simulator = cirq.Simulator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thirdly, we define the `reuploading quantum model`, which has the same structure as the quantum neural network, but with an extra encoding layer inbetween every layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildReuploadQuantumModel(encoding: np.array, parameters: np.array, depth : int, n_qubits : int) -> None:\n",
    "    qubits = cirq.LineQubit.range(n_qubits)\n",
    "\n",
    "    \n",
    "    #encoding layer\n",
    "    yield [cirq.ry(encoding[i])(qubits[i]) for i in range(n_qubits)]\n",
    "    yield [cirq.rx(encoding[i])(qubits[i]) for i in range(n_qubits)]\n",
    "\n",
    "\n",
    "\n",
    "    #variational layer\n",
    "    for l in range(depth):\n",
    "        for i in range(n_qubits):\n",
    "            yield cirq.rx(parameters[i + l*n_qubits])(qubits[i])\n",
    "        for i in range(n_qubits-1):\n",
    "            yield cirq.CZ(qubits[i], qubits[i+1])\n",
    "\n",
    "        yield [cirq.ry(encoding[i])(qubits[i]) for i in range(n_qubits)]\n",
    "        yield [cirq.rx(encoding[i])(qubits[i]) for i in range(n_qubits)]\n",
    "\n",
    "\n",
    "    #readout layer\n",
    "    yield cirq.measure(qubits[0], key='z0')\n",
    "\n",
    "simulator = cirq.Simulator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the quantum neural network output needs to be simulated, we need to built these for each of the QNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runCircuit(data : np.array, parameters : np.array) -> float:\n",
    "\n",
    "\n",
    "    quantumModel = cirq.Circuit(buildQuantumModel(data, parameters, depth, n_qubits))\n",
    "    result = simulator.run(quantumModel, repetitions=100)\n",
    "\n",
    "    result = np.mean(result.measurements['z0'])\n",
    "\n",
    "    return result\n",
    "\n",
    "def runPartialCircuit(data : np.array, parameters : np.array) -> float:\n",
    "\n",
    "    \n",
    "    quantumModel = cirq.Circuit(buildPartialQuantumModel(data, parameters, depth, n_qubits))\n",
    "    result = simulator.run(quantumModel, repetitions=100)\n",
    "    \n",
    "    result = np.mean(result.measurements['z0'])\n",
    "    \n",
    "    return result\n",
    "\n",
    "def runReuploadCircuit(data : np.array, parameters : np.array) -> float:\n",
    "\n",
    "    \n",
    "    quantumModel = cirq.Circuit(buildReuploadQuantumModel(data, parameters, depth, n_qubits))\n",
    "    result = simulator.run(quantumModel, repetitions=100)\n",
    "    \n",
    "    result = np.mean(result.measurements['z0'])\n",
    "    \n",
    "    return result\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classical Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we define the classical neural network. This is a simple neural network with a simple leaky relu dense layers and a sigmoid output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildClassicalModel(depth : int , trainable : bool) -> tf.keras.Sequential:\n",
    "\n",
    "    classicModel = tf.keras.Sequential()\n",
    "    \n",
    "    for l in range(depth):\n",
    "        classicModel.add(tf.keras.layers.Dense(n_qubits, activation='leaky_relu', trainable=trainable))\n",
    "\n",
    "    classicModel.add(tf.keras.layers.Dense(1, activation='sigmoid', trainable=trainable))\n",
    "\n",
    "    return classicModel\n",
    "\n",
    "classicModel = buildClassicalModel(depth, True)\n",
    "dataClassicalModel = buildClassicalModel(depth, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we sample a define a sampler, creating the 3-dimensional dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateClassicSamples(samples : int) -> np.array:\n",
    "\n",
    "    empty = np.array([])\n",
    "\n",
    "    for i in range(samples):\n",
    "        empty = np.append(empty, np.random.uniform(-1, 1, 2))\n",
    "\n",
    "    empty = empty.reshape(samples, 2)\n",
    "    \n",
    "\n",
    "    data = np.zeros((empty.shape[0], empty.shape[1] + 1))\n",
    "    data[:,:2] = empty\n",
    "    data[:,-1] = empty[:,0]*empty[:,1]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we classify 1000 of these samples using the fixed classical neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataClassicalModel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "classicData = generateClassicSamples(1000)\n",
    "\n",
    "\n",
    "classicLabels = dataClassicalModel.predict(classicData)\n",
    "onelabel = zerolabel = 0\n",
    "\n",
    "for i in range(len(classicLabels)):\n",
    "    if classicLabels[i] > 0.498:\n",
    "        classicLabels[i] = 1\n",
    "        onelabel += 1\n",
    "    else:\n",
    "        classicLabels[i] = 0\n",
    "        zerolabel += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The split between the data can be shown in the 2d-space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Classic Data')\n",
    "ax.set_ylabel('x2')\n",
    "ax.set_xlabel('x1')\n",
    "sns.scatterplot(x=classicData[:,0], y=classicData[:,1], hue=classicLabels.flatten(), ax=ax)\n",
    "fig.savefig('figures/classicData.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we test on the classical model. Lastly, we initialize the COBYLA optimizer and train the three quantum neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(classicData, classicLabels, test_size=0.33, random_state=4)\n",
    "\n",
    "classicModel = buildClassicalModel(depth, True)\n",
    "classicModel.compile(optimizer='adam', loss='MeanSquaredError', metrics=['accuracy'])\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "classicModel.fit(X_train, y_train, epochs=50)\n",
    "end = time.time()\n",
    "print(classicModel.evaluate(X_test, y_test))\n",
    "print(\"Time: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateLoss(parameters : np.array, data: np.array, labels: np.array) -> float:\n",
    "\n",
    "    probs = [runCircuit(data[i,:], parameters) for i in range(len(data))]\n",
    "\n",
    "    for i in range(len(probs)):\n",
    "        if probs[i] > 0.5:\n",
    "            probs[i] = 1\n",
    "        else:\n",
    "            probs[i] = 0\n",
    "\n",
    "    return mse(labels, probs)\n",
    "    \n",
    "\n",
    "cost = []\n",
    "\n",
    "\n",
    "def optimize(parameters : np.array) -> float:\n",
    "\n",
    "    singleCost = calculateLoss(parameters, X_train, y_train)\n",
    "    cost.append(singleCost)\n",
    "\n",
    "    return singleCost\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "result = minimize(optimize, randomRotations, method='COBYLA', options={\"maxiter\": 50})\n",
    "predictedLabels = [runCircuit(X_test[i,:], result.x) for i in range(len(X_test))]\n",
    "predictedLabels = [1 if predictedLabels[i] > 0.5 else 0 for i in range(len(predictedLabels))]\n",
    "end = time.time()\n",
    "print(\"MSE: \", str(mse(y_test, predictedLabels)))\n",
    "print(\"Time\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculatePartialLoss(parameters : np.array, data: np.array, labels: np.array) -> float:\n",
    "\n",
    "    probs = [runPartialCircuit(data[i,:], parameters) for i in range(len(data))]\n",
    "\n",
    "    for i in range(len(probs)):\n",
    "        if probs[i] > 0.5:\n",
    "            probs[i] = 1\n",
    "        else:\n",
    "            probs[i] = 0\n",
    "\n",
    "    return mse(labels, probs)\n",
    "\n",
    "\n",
    "cost = []\n",
    "\n",
    "\n",
    "def optimizePartial(parameters : np.array) -> float:\n",
    "    \n",
    "        singleCost = calculatePartialLoss(parameters, X_train, y_train)\n",
    "        cost.append(singleCost)\n",
    "    \n",
    "        return singleCost\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "result = minimize(optimizePartial, randomRotations, method='COBYLA', options={\"maxiter\": 50})\n",
    "predictedLabels = [runPartialCircuit(X_test[i,:], result.x) for i in range(len(X_test))]\n",
    "predictedLabels = [1 if predictedLabels[i] > 0.5 else 0 for i in range(len(predictedLabels))]\n",
    "end = time.time()\n",
    "print(\"MSE: \", str(mse(y_test, predictedLabels)))\n",
    "print(\"Time\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateReuploadLoss(parameters : np.array, data: np.array, labels: np.array) -> float:\n",
    "\n",
    "\n",
    "    probs = [runReuploadCircuit(data[i,:], parameters) for i in range(len(data))]\n",
    "\n",
    "    for i in range(len(probs)):\n",
    "        if probs[i] > 0.5:\n",
    "            probs[i] = 1\n",
    "        else:\n",
    "            probs[i] = 0\n",
    "\n",
    "    return mse(labels, probs)\n",
    "\n",
    "\n",
    "cost = []\n",
    "\n",
    "\n",
    "def optimizeReupload(parameters : np.array) -> float:\n",
    "        \n",
    "        singleCost = calculateReuploadLoss(parameters, X_train, y_train)\n",
    "        cost.append(singleCost)\n",
    "        \n",
    "        return singleCost\n",
    "\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "result = minimize(optimizeReupload, randomRotations, method='COBYLA', options={\"maxiter\": 50})\n",
    "predictedLabels = [runReuploadCircuit(X_test[i,:], result.x) for i in range(len(X_test))]\n",
    "predictedLabels = [1 if predictedLabels[i] > 0.5 else 0 for i in range(len(predictedLabels))]\n",
    "end = time.time()\n",
    "print(\"MSE: \", str(mse(y_test, predictedLabels)))\n",
    "print(\"Time\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the same process as with the classical data, only now sampling between 0 and 2*pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateQuantumSamples(samples : int) -> np.array:\n",
    "\n",
    "    empty = np.array([])\n",
    "\n",
    "    for i in range(samples):\n",
    "        empty = np.append(empty, np.random.uniform(0, 2*np.pi, 2))\n",
    "\n",
    "    empty = empty.reshape(samples, 2)\n",
    "    \n",
    "\n",
    "    data = np.zeros((empty.shape[0], empty.shape[1] + 1))\n",
    "    data[:,:2] = empty\n",
    "    data[:,-1] = empty[:,0]*empty[:,1]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantumData = generateQuantumSamples(1000)\n",
    "quantumLabels = [runCircuit(quantumData[i,:], randomRotations) for i in range(len(quantumData))]\n",
    "\n",
    "onelabel = zerolabel = 0\n",
    "\n",
    "for i in range(len(quantumLabels)):\n",
    "    if quantumLabels[i] > 0.5:\n",
    "        quantumLabels[i] = 1\n",
    "        onelabel += 1\n",
    "    else:\n",
    "        quantumLabels[i] = 0\n",
    "        zerolabel += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Basic Quantum Neural Network Generated Data')\n",
    "ax.set_ylabel('x2')\n",
    "ax.set_xlabel('x1')\n",
    "sns.scatterplot(x=quantumData[:,0], y=quantumData[:,1], hue=quantumLabels, ax=ax)\n",
    "fig.savefig('figures/quantumData.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partialQuantumData = generateQuantumSamples(1000)\n",
    "partialQuantumLabels = [runPartialCircuit(quantumData[i,:], randomRotations) for i in range(len(quantumData))]\n",
    "\n",
    "onelabel = zerolabel = 0\n",
    "\n",
    "for i in range(len(partialQuantumLabels)):\n",
    "    if partialQuantumLabels[i] > 0.5:\n",
    "        partialQuantumLabels[i] = 1\n",
    "        onelabel += 1\n",
    "    else:\n",
    "        partialQuantumLabels[i] = 0\n",
    "        zerolabel += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Partial Quantum Neural Network Generated Data')\n",
    "ax.set_ylabel('x2')\n",
    "ax.set_xlabel('x1')\n",
    "sns.scatterplot(x=partialQuantumData[:,0], y=partialQuantumData[:,1], hue=partialQuantumLabels, ax=ax)\n",
    "fig.savefig('figures/partialQuantumData.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuploadQuantumData = generateQuantumSamples(1000)\n",
    "reuploadQuantumLabels = [runReuploadCircuit(quantumData[i,:], randomRotations) for i in range(len(quantumData))]\n",
    "\n",
    "onelabel = zerolabel = 0\n",
    "\n",
    "for i in range(len(reuploadQuantumLabels)):\n",
    "    if reuploadQuantumLabels[i] > 0.5:\n",
    "        reuploadQuantumLabels[i] = 1\n",
    "        onelabel += 1\n",
    "    else:\n",
    "        reuploadQuantumLabels[i] = 0\n",
    "        zerolabel += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Reuploading Quantum Neural Network Generated Data')\n",
    "ax.set_ylabel('x2')\n",
    "ax.set_xlabel('x1')\n",
    "sns.scatterplot(x=reuploadQuantumData[:,0], y=reuploadQuantumData[:,1], hue=reuploadQuantumLabels, ax=ax)\n",
    "fig.savefig('figures/reuploadQuantumData.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as the training and testing on the classical dataset, now for each of the datasets generated by the quantum neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(quantumData, quantumLabels, test_size=0.33, random_state=4)\n",
    "\n",
    "classicModel = buildClassicalModel(depth, True)\n",
    "classicModel.compile(optimizer='adam', loss='MeanSquaredError', metrics=['accuracy'])\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "classicModel.fit(X_train, y_train, epochs=50)\n",
    "end = time.time()\n",
    "print(classicModel.evaluate(X_test, y_test))\n",
    "print(\"Time: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateLoss(parameters : np.array, data: np.array, labels: np.array) -> float:\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    probs = [runCircuit(data[i,:], parameters) for i in range(len(data))]\n",
    "\n",
    "    for i in range(len(probs)):\n",
    "        if probs[i] > 0.5:\n",
    "            probs[i] = 1\n",
    "        else:\n",
    "            probs[i] = 0\n",
    "\n",
    "    return mse(labels, probs)\n",
    "    \n",
    "\n",
    "cost = []\n",
    "\n",
    "\n",
    "def optimize(parameters : np.array) -> float:\n",
    "\n",
    "    singleCost = calculateLoss(parameters, X_train, y_train)\n",
    "    cost.append(singleCost)\n",
    "\n",
    "    return singleCost\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "result = minimize(optimize, randomRotations, method='COBYLA', options={\"maxiter\": 50})\n",
    "predictedLabels = [runCircuit(X_test[i,:], result.x) for i in range(len(X_test))]\n",
    "predictedLabels = [1 if predictedLabels[i] > 0.5 else 0 for i in range(len(predictedLabels))]\n",
    "end = time.time()\n",
    "print(\"MSE: \", str(mse(y_test, predictedLabels)))\n",
    "print(\"Time\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculatePartialLoss(parameters : np.array, data: np.array, labels: np.array) -> float:\n",
    "\n",
    "    probs = [runPartialCircuit(data[i,:], parameters) for i in range(len(data))]\n",
    "\n",
    "    for i in range(len(probs)):\n",
    "        if probs[i] > 0.5:\n",
    "            probs[i] = 1\n",
    "        else:\n",
    "            probs[i] = 0\n",
    "\n",
    "    return mse(labels, probs)\n",
    "\n",
    "\n",
    "cost = []\n",
    "\n",
    "\n",
    "def optimizePartial(parameters : np.array) -> float:\n",
    "    \n",
    "        singleCost = calculatePartialLoss(parameters, X_train, y_train)\n",
    "        cost.append(singleCost)\n",
    "    \n",
    "        return singleCost\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "result = minimize(optimizePartial, randomRotations, method='COBYLA', options={\"maxiter\": 50})\n",
    "predictedLabels = [runPartialCircuit(X_test[i,:], result.x) for i in range(len(X_test))]\n",
    "predictedLabels = [1 if predictedLabels[i] > 0.5 else 0 for i in range(len(predictedLabels))]\n",
    "end = time.time()\n",
    "print(\"MSE: \", str(mse(y_test, predictedLabels)))\n",
    "print(\"Time\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateReuploadLoss(parameters : np.array, data: np.array, labels: np.array) -> float:\n",
    "\n",
    "    probs = [runReuploadCircuit(data[i,:], parameters) for i in range(len(data))]\n",
    "\n",
    "    for i in range(len(probs)):\n",
    "        if probs[i] > 0.5:\n",
    "            probs[i] = 1\n",
    "        else:\n",
    "            probs[i] = 0\n",
    "\n",
    "    return mse(labels, probs)\n",
    "\n",
    "\n",
    "cost = []\n",
    "\n",
    "\n",
    "def optimizeReupload(parameters : np.array) -> float:\n",
    "        \n",
    "        singleCost = calculateReuploadLoss(parameters, X_train, y_train)\n",
    "        cost.append(singleCost)\n",
    "        \n",
    "        return singleCost\n",
    "\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "result = minimize(optimizeReupload, randomRotations, method='COBYLA', options={\"maxiter\": 50})\n",
    "predictedLabels = [runReuploadCircuit(X_test[i,:], result.x) for i in range(len(X_test))]\n",
    "predictedLabels = [1 if predictedLabels[i] > 0.5 else 0 for i in range(len(predictedLabels))]\n",
    "end = time.time()\n",
    "print(\"MSE: \", str(mse(y_test, predictedLabels)))\n",
    "print(\"Time\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(partialQuantumData, partialQuantumLabels, test_size=0.33, random_state=4)\n",
    "\n",
    "classicModel = buildClassicalModel(depth, True)\n",
    "classicModel.compile(optimizer='adam', loss='MeanSquaredError', metrics=['accuracy'])\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "classicModel.fit(X_train, y_train, epochs=50)\n",
    "end = time.time()\n",
    "print(classicModel.evaluate(X_test, y_test))\n",
    "print(\"Time: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateLoss(parameters : np.array, data: np.array, labels: np.array) -> float:\n",
    "\n",
    "    probs = [runCircuit(data[i,:], parameters) for i in range(len(data))]\n",
    "\n",
    "    for i in range(len(probs)):\n",
    "        if probs[i] > 0.5:\n",
    "            probs[i] = 1\n",
    "        else:\n",
    "            probs[i] = 0\n",
    "\n",
    "    return mse(labels, probs)\n",
    "    \n",
    "\n",
    "cost = []\n",
    "\n",
    "\n",
    "def optimize(parameters : np.array) -> float:\n",
    "\n",
    "    singleCost = calculateLoss(parameters, X_train, y_train)\n",
    "    cost.append(singleCost)\n",
    "\n",
    "    return singleCost\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "result = minimize(optimize, randomRotations, method='COBYLA', options={\"maxiter\": 50})\n",
    "predictedLabels = [runCircuit(X_test[i,:], result.x) for i in range(len(X_test))]\n",
    "predictedLabels = [1 if predictedLabels[i] > 0.5 else 0 for i in range(len(predictedLabels))]\n",
    "end = time.time()\n",
    "print(\"MSE: \", str(mse(y_test, predictedLabels)))\n",
    "print(\"Time\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculatePartialLoss(parameters : np.array, data: np.array, labels: np.array) -> float:\n",
    "\n",
    "    probs = [runPartialCircuit(data[i,:], parameters) for i in range(len(data))]\n",
    "\n",
    "    for i in range(len(probs)):\n",
    "        if probs[i] > 0.5:\n",
    "            probs[i] = 1\n",
    "        else:\n",
    "            probs[i] = 0\n",
    "\n",
    "    return mse(labels, probs)\n",
    "\n",
    "\n",
    "cost = []\n",
    "\n",
    "\n",
    "def optimizePartial(parameters : np.array) -> float:\n",
    "    \n",
    "        singleCost = calculatePartialLoss(parameters, X_train, y_train)\n",
    "        cost.append(singleCost)\n",
    "    \n",
    "        return singleCost\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "result = minimize(optimizePartial, randomRotations, method='COBYLA', options={\"maxiter\": 50})\n",
    "predictedLabels = [runPartialCircuit(X_test[i,:], result.x) for i in range(len(X_test))]\n",
    "predictedLabels = [1 if predictedLabels[i] > 0.5 else 0 for i in range(len(predictedLabels))]\n",
    "end = time.time()\n",
    "print(\"MSE: \", str(mse(y_test, predictedLabels)))\n",
    "print(\"Time\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateReuploadLoss(parameters : np.array, data: np.array, labels: np.array) -> float:\n",
    "\n",
    "    probs = [runReuploadCircuit(data[i,:], parameters) for i in range(len(data))]\n",
    "\n",
    "    for i in range(len(probs)):\n",
    "        if probs[i] > 0.5:\n",
    "            probs[i] = 1\n",
    "        else:\n",
    "            probs[i] = 0\n",
    "\n",
    "    return mse(labels, probs)\n",
    "\n",
    "\n",
    "cost = []\n",
    "\n",
    "\n",
    "def optimizeReupload(parameters : np.array) -> float:\n",
    "        \n",
    "        singleCost = calculateReuploadLoss(parameters, X_train, y_train)\n",
    "        cost.append(singleCost)\n",
    "        \n",
    "        return singleCost\n",
    "\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "result = minimize(optimizeReupload, randomRotations, method='COBYLA', options={\"maxiter\": 50})\n",
    "predictedLabels = [runReuploadCircuit(X_test[i,:], result.x) for i in range(len(X_test))]\n",
    "predictedLabels = [1 if predictedLabels[i] > 0.5 else 0 for i in range(len(predictedLabels))]\n",
    "end = time.time()\n",
    "print(\"MSE: \", str(mse(y_test, predictedLabels)))\n",
    "print(\"Time\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reuploadQuantumData, reuploadQuantumLabels, test_size=0.33, random_state=4)\n",
    "\n",
    "classicModel = buildClassicalModel(depth, True)\n",
    "classicModel.compile(optimizer='adam', loss='MeanSquaredError', metrics=['accuracy'])\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "classicModel.fit(X_train, y_train, epochs=50)\n",
    "end = time.time()\n",
    "print(classicModel.evaluate(X_test, y_test))\n",
    "print(\"Time: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateLoss(parameters : np.array, data: np.array, labels: np.array) -> float:\n",
    "\n",
    "    probs = [runCircuit(data[i,:], parameters) for i in range(len(data))]\n",
    "\n",
    "    for i in range(len(probs)):\n",
    "        if probs[i] > 0.5:\n",
    "            probs[i] = 1\n",
    "        else:\n",
    "            probs[i] = 0\n",
    "\n",
    "    return mse(labels, probs)\n",
    "    \n",
    "\n",
    "cost = []\n",
    "\n",
    "\n",
    "def optimize(parameters : np.array) -> float:\n",
    "\n",
    "    singleCost = calculateLoss(parameters, X_train, y_train)\n",
    "    cost.append(singleCost)\n",
    "\n",
    "    return singleCost\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "result = minimize(optimize, randomRotations, method='COBYLA', options={\"maxiter\": 50})\n",
    "predictedLabels = [runCircuit(X_test[i,:], result.x) for i in range(len(X_test))]\n",
    "predictedLabels = [1 if predictedLabels[i] > 0.5 else 0 for i in range(len(predictedLabels))]\n",
    "end = time.time()\n",
    "print(\"MSE: \", str(mse(y_test, predictedLabels)))\n",
    "print(\"Time\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculatePartialLoss(parameters : np.array, data: np.array, labels: np.array) -> float:\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    probs = [runPartialCircuit(data[i,:], parameters) for i in range(len(data))]\n",
    "\n",
    "    for i in range(len(probs)):\n",
    "        if probs[i] > 0.5:\n",
    "            probs[i] = 1\n",
    "        else:\n",
    "            probs[i] = 0\n",
    "\n",
    "    return mse(labels, probs)\n",
    "\n",
    "\n",
    "cost = []\n",
    "\n",
    "\n",
    "def optimizePartial(parameters : np.array) -> float:\n",
    "    \n",
    "        singleCost = calculatePartialLoss(parameters, X_train, y_train)\n",
    "        cost.append(singleCost)\n",
    "    \n",
    "        return singleCost\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "result = minimize(optimizePartial, randomRotations, method='COBYLA', options={\"maxiter\": 50})\n",
    "predictedLabels = [runPartialCircuit(X_test[i,:], result.x) for i in range(len(X_test))]\n",
    "predictedLabels = [1 if predictedLabels[i] > 0.5 else 0 for i in range(len(predictedLabels))]\n",
    "end = time.time()\n",
    "print(\"MSE: \", str(mse(y_test, predictedLabels)))\n",
    "print(\"Time\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateReuploadLoss(parameters : np.array, data: np.array, labels: np.array) -> float:\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    probs = [runReuploadCircuit(data[i,:], parameters) for i in range(len(data))]\n",
    "\n",
    "    for i in range(len(probs)):\n",
    "        if probs[i] > 0.5:\n",
    "            probs[i] = 1\n",
    "        else:\n",
    "            probs[i] = 0\n",
    "\n",
    "    return mse(labels, probs)\n",
    "\n",
    "\n",
    "cost = []\n",
    "\n",
    "\n",
    "def optimizeReupload(parameters : np.array) -> float:\n",
    "        \n",
    "        singleCost = calculateReuploadLoss(parameters, X_train, y_train)\n",
    "        cost.append(singleCost)\n",
    "        \n",
    "        return singleCost\n",
    "\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "result = minimize(optimizeReupload, randomRotations, method='COBYLA', options={\"maxiter\": 50})\n",
    "predictedLabels = [runReuploadCircuit(X_test[i,:], result.x) for i in range(len(X_test))]\n",
    "predictedLabels = [1 if predictedLabels[i] > 0.5 else 0 for i in range(len(predictedLabels))]\n",
    "end = time.time()\n",
    "print(\"MSE: \", str(mse(y_test, predictedLabels)))\n",
    "print(\"Time\", end - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aQa-Final-Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
